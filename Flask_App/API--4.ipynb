{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install it only once.\n",
    "pip install cmake\n",
    "pip install dlib-19.24.1-cp311-cp311-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50779769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drowsiness Model is being loaded!\n",
      "Distraction Model is being loaded!\n",
      "Road Model is being loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.11:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:10] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:15] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:16] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:18] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:19] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:20] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:22] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:03:50] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.11 - - [15/Feb/2024 15:04:01] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ExifTags\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from flask import request, jsonify, Flask\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "\n",
    "\n",
    "# App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# function to load the models\n",
    "def load_model_fn(path):\n",
    "    model = load_model(path)\n",
    "    print('Model loaded!')\n",
    "    return model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# function to resize our image\n",
    "def preprocess_image(image, target_size):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "# ------------------------------------------------------------\n",
    "def exif_transpose(img):\n",
    "    try:\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation]=='Orientation':\n",
    "                break\n",
    "        e = img._getexif()\n",
    "        if e is not None:\n",
    "            exif=dict(e.items())\n",
    "            if orientation in exif:\n",
    "                if exif[orientation] == 3:\n",
    "                    img = img.transpose(Image.ROTATE_180)\n",
    "                elif exif[orientation] == 6:\n",
    "                    img = img.transpose(Image.ROTATE_270)\n",
    "                elif exif[orientation] == 8:\n",
    "                    img = img.transpose(Image.ROTATE_90)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in exif_transpose: {e}\")\n",
    "    return img\n",
    "# ------------------------------------------------------------\n",
    "predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def crop_mouth(img, Target_Size=(224, 224)):\n",
    "    \n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        for k, d in enumerate(dets):\n",
    "            # Get the landmarks/parts for the face in box d.\n",
    "            shape = predictor(img, d)\n",
    "            # The next lines of code just get the coordinates for the mouth\n",
    "            # and crop the mouth from the image.This part can probably be optimised\n",
    "            # by taking only the outer most points.\n",
    "            xmouthpoints = [shape.part(x).x for x in range(48,67)]\n",
    "            ymouthpoints = [shape.part(x).y for x in range(48,67)]\n",
    "            maxx = max(xmouthpoints)\n",
    "            minx = min(xmouthpoints)\n",
    "            maxy = max(ymouthpoints)\n",
    "            miny = min(ymouthpoints) \n",
    "\n",
    "            # to show the mouth properly pad both sides\n",
    "            pad = 10\n",
    "\n",
    "            crop_image = img[miny-pad:maxy+pad,minx-pad:maxx+pad]\n",
    "            RGB_image = cv2.cvtColor(crop_image, cv2.COLOR_BGR2RGB)\n",
    "            resized_image = cv2.resize(RGB_image,Target_Size)\n",
    "            return resized_image\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def crop_eye(img, Target_Size=(224, 224)):\n",
    "    \n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        for k, d in enumerate(dets):\n",
    "            # Get the landmarks/parts for the face in box d.\n",
    "            shape = predictor(img, d)\n",
    "            # The next lines of code just get the coordinates for the mouth\n",
    "            # and crop the eye from the image.This part can probably be optimised\n",
    "            # by taking only the outer most points.\n",
    "            xmouthpoints = [shape.part(18).x, shape.part(19).x, shape.part(20).x, shape.part(21).x, shape.part(36).x, shape.part(37).x, shape.part(38).x, shape.part(39).x, shape.part(40).x,shape.part(41).x]\n",
    "            ymouthpoints = [shape.part(18).y, shape.part(19).y, shape.part(20).y, shape.part(21).y, shape.part(36).y, shape.part(37).y, shape.part(38).y, shape.part(39).y, shape.part(40).y,shape.part(41).y]\n",
    "            maxx = max(xmouthpoints)\n",
    "            minx = min(xmouthpoints)\n",
    "            maxy = max(ymouthpoints)\n",
    "            miny = min(ymouthpoints) \n",
    "\n",
    "            # to show the mouth properly pad both sides\n",
    "            pad = 10\n",
    "\n",
    "            crop_image = img[miny-pad:maxy+pad,minx-pad:maxx+pad]\n",
    "            RGB_image = cv2.cvtColor(crop_image, cv2.COLOR_BGR2RGB)\n",
    "            resized_image = cv2.resize(RGB_image,Target_Size)\n",
    "            return resized_image\n",
    "    else:\n",
    "        return None\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Loading the models !!!\n",
    "print('Drowsiness Model is being loaded!')\n",
    "print('Distraction Model is being loaded!')\n",
    "print('Road Model is being loaded!')\n",
    "\n",
    "distraction_CNN_model = load_model_fn('CNNModelwithDataAugmentation.h5')\n",
    "drowsiness_model = load_model_fn('drowsinessmodel.h5')\n",
    "road_model = load_model_fn('vehicle.h5')\n",
    "\n",
    "# ###################################################################################################\n",
    "#         mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "\n",
    "# 1- #Drowsiness API\n",
    "@app.route('/drowsiness', methods=['POST'])\n",
    "def predict_drowsiness():\n",
    "    message = request.get_json(force=True)\n",
    "    encoded = message['image']\n",
    "    decoded = base64.b64decode(encoded)\n",
    "    image_received = Image.open(io.BytesIO(decoded))\n",
    "\n",
    "    # Correct the orientation\n",
    "    image_received = exif_transpose(image_received)\n",
    "    image_arr = np.array(image_received)\n",
    "    mapping_list = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\n",
    "    try:\n",
    "        #crop eyes\n",
    "        eye_right = crop_eye(image_arr)\n",
    "        # Reshape and normalize the image\n",
    "        img_batch_right_eye = np.expand_dims(eye_right, axis=0)\n",
    "        normalized_eye = img_batch_right_eye / 255\n",
    "        # Make prediction for right eye\n",
    "        prediction_eye_right = drowsiness_model.predict(normalized_eye).tolist()\n",
    "        index_of_eye_right = np.argmax(prediction_eye_right)\n",
    "        largest_eye = max(prediction_eye_right[0])\n",
    "        if largest_eye > 0.50:\n",
    "            result_right = mapping_list[index_of_eye_right]\n",
    "        else:\n",
    "            result_right = 'Weak Prediction'\n",
    "        \n",
    "    except:\n",
    "        result_right = \"Couldn't Crop the Eye\"\n",
    "        \n",
    "    try:\n",
    "        #crop mouth and resize\n",
    "        mouth_image = crop_mouth(image_arr)\n",
    "        img_batch_mouth = np.expand_dims(mouth_image, axis=0)\n",
    "        normalized_mouth = img_batch_mouth / 255\n",
    "        #make mouth prediction\n",
    "        prediction_mouth = drowsiness_model.predict(normalized_mouth).tolist()\n",
    "        index_of_mouth = np.argmax(prediction_mouth[0])\n",
    "        largest_mouth = max(prediction_mouth[0])\n",
    "        if largest_mouth > 0.50:\n",
    "            result_mouth = mapping_list[index_of_mouth]\n",
    "        else:\n",
    "            result_mouth = 'Weak Prediction'\n",
    "        \n",
    "    except:\n",
    "        result_mouth = \"Couldn't Crop the Mouth\"\n",
    "    \n",
    "    # Initial value for final_result\n",
    "    final_result = \"\"\n",
    "    \n",
    "    if result_mouth==\"yawn\" or result_right == \"Closed\":\n",
    "        final_result = \"Drowsy\"\n",
    "    else:\n",
    "        final_result = 'Awake'\n",
    "    \n",
    "    return jsonify(final_result)\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# Define a global variable to store road result\n",
    "global road_result\n",
    "road_result = None\n",
    "\n",
    "# 2- Distraction API\n",
    "@app.route('/distraction', methods=['POST'])\n",
    "def predict_driver_distraction():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode message'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    processed_image = preprocess_image(image, target_size=(224, 224))\n",
    "    try:\n",
    "        prediction = distraction_CNN_model.predict(processed_image).tolist()\n",
    "        print(prediction)\n",
    "    except:\n",
    "        result = 'The model could not predict the Image'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    label = ['normal driving',\n",
    "             'texting - right',\n",
    "             'talking on the phone - right',\n",
    "             'texting - left',\n",
    "             'talking on the phone - left',\n",
    "             'operating the radio',\n",
    "             'drinking',\n",
    "             'reaching behind',\n",
    "             'hair and makeup',\n",
    "             'talking to passenger']\n",
    "    \n",
    "    largest_value = max(prediction[0])\n",
    "    if largest_value >= .50 :\n",
    "        max_index = np.argmax(prediction)\n",
    "        result = label[max_index]\n",
    "    elif largest_value < .50:\n",
    "        result = 'Unknown'\n",
    "        \n",
    "\n",
    "    global road_result\n",
    "    if road_result == 'Vehicles':\n",
    "        if result != 'normal driving':\n",
    "            final_result = 'Warning!!! There is an object'\n",
    "        else:\n",
    "            final_result = 'Safe Driving'\n",
    "        return jsonify(final_result)\n",
    "    else:\n",
    "        # If road prediction is 'Non-Vehicles', return 'result' of distraction model\n",
    "        return jsonify(result)\n",
    "\n",
    "        \n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# 3- Road API\n",
    "@app.route('/road', methods=['POST'])\n",
    "def predict_road():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode message'\n",
    "        return jsonify(result)\n",
    "\n",
    "    # Make prediction for road\n",
    "    processed_image_road = preprocess_image(image, target_size=(150, 150))\n",
    "    prediction_road = road_model.predict(processed_image_road).tolist()\n",
    "    response_road = {\n",
    "        'prediction': {\n",
    "            'Non-Vehicles': prediction_road[0][0],\n",
    "            'Vehicles': prediction_road[0][1]\n",
    "        }\n",
    "    }\n",
    "    global road_result\n",
    "    road_result = max(response_road['prediction'], key=response_road['prediction'].get)\n",
    "#     road_result = 'Vehicles'\n",
    "    \n",
    "    return jsonify(road_result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
